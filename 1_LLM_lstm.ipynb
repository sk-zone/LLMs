{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#Load JSONL Dataset\n",
        "with open(\"data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = [json.loads(line) for line in f]\n",
        "\n",
        "#Filter English Data Robustly\n",
        "english_data = [entry for entry in data if entry[\"language\"].lower().startswith(\"en\")]\n",
        "print(f\"Filtered {len(english_data)} English entries.\")\n",
        "\n",
        "texts = [entry[\"text\"] for entry in english_data]\n",
        "labels = [entry[\"labels\"] for entry in english_data]\n",
        "\n",
        "if len(texts) == 0:\n",
        "    raise ValueError(\"No English entries found. Check your language filtering step.\")\n",
        "\n",
        "#Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels = label_encoder.fit_transform(labels)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "categorical_labels = to_categorical(encoded_labels, num_classes=num_classes)\n",
        "\n",
        "#Tokenize and Pad\n",
        "tokenizer = Tokenizer(num_words=20000, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "maxlen = 100\n",
        "padded_sequences = pad_sequences(sequences, maxlen=maxlen, padding=\"post\", truncating=\"post\")\n",
        "\n",
        "#Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    padded_sequences, categorical_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "#Load GloVe Embeddings with Auto-Dimension Detection\n",
        "embedding_index = {}\n",
        "glove_path = \"glove.6B.100d.txt\"\n",
        "\n",
        "with open(glove_path, encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.strip().split()\n",
        "        if len(values) < 2:\n",
        "            continue\n",
        "        word = values[0]\n",
        "        vector = values[1:]\n",
        "        try:\n",
        "            vector = np.asarray(vector, dtype=\"float32\")\n",
        "        except ValueError:\n",
        "            continue\n",
        "        embedding_index[word] = vector\n",
        "\n",
        "embedding_dim = len(next(iter(embedding_index.values())))\n",
        "print(f\"Loaded {len(embedding_index)} word vectors of dimension {embedding_dim}\")\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(20000, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "skipped = 0\n",
        "for word, i in word_index.items():\n",
        "    if i >= 20000:\n",
        "        continue\n",
        "    vector = embedding_index.get(word)\n",
        "    if vector is not None and len(vector) == embedding_dim:\n",
        "        embedding_matrix[i] = vector\n",
        "    else:\n",
        "        skipped += 1\n",
        "\n",
        "print(f\"Skipped {skipped} words due to missing/mismatched vectors.\")\n",
        "\n",
        "#Build the Improved LSTM Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=num_words, output_dim=embedding_dim,\n",
        "              weights=[embedding_matrix], input_length=maxlen, trainable=True),\n",
        "    Bidirectional(LSTM(128, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "#Add Early Stopping and Train\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=25,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop]\n",
        ")\n",
        "\n",
        "#Evaluate Model on Test Set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nFinal Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "#Sample Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"\\n--- Sample Predictions ---\")\n",
        "for i in range(5):\n",
        "    decoded_text = tokenizer.sequences_to_texts([X_test[i]])[0]\n",
        "    actual = label_encoder.inverse_transform([y_true_labels[i]])[0]\n",
        "    predicted = label_encoder.inverse_transform([y_pred_labels[i]])[0]\n",
        "    print(f\"\\nText:\\n{decoded_text[:300]}...\")\n",
        "    print(f\"Actual: {actual}\")\n",
        "    print(f\"Predicted: {predicted}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Oh0YdphZCNkC",
        "outputId": "ca99fae3-1c34-441e-ece5-8a12b542dde4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered 1237 English entries.\n",
            "Loaded 400000 word vectors of dimension 100\n",
            "Skipped 839 words due to missing/mismatched vectors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_28\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_28\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_28 (\u001b[38;5;33mEmbedding\u001b[0m)             │ ?                           │       \u001b[38;5;34m2,000,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_22 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)                 │ ?                           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ ?                           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,000,000\u001b[0m (7.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> (7.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,000,000\u001b[0m (7.63 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> (7.63 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 459ms/step - accuracy: 0.1677 - loss: 2.1444 - val_accuracy: 0.3333 - val_loss: 2.0332\n",
            "Epoch 2/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 414ms/step - accuracy: 0.2669 - loss: 1.9691 - val_accuracy: 0.3636 - val_loss: 1.8325\n",
            "Epoch 3/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 420ms/step - accuracy: 0.3753 - loss: 1.7308 - val_accuracy: 0.4242 - val_loss: 1.6992\n",
            "Epoch 4/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 519ms/step - accuracy: 0.5031 - loss: 1.4593 - val_accuracy: 0.4040 - val_loss: 1.5111\n",
            "Epoch 5/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 539ms/step - accuracy: 0.5407 - loss: 1.3128 - val_accuracy: 0.4545 - val_loss: 1.4636\n",
            "Epoch 6/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 412ms/step - accuracy: 0.6373 - loss: 1.0872 - val_accuracy: 0.4646 - val_loss: 1.4319\n",
            "Epoch 7/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 412ms/step - accuracy: 0.6668 - loss: 0.9989 - val_accuracy: 0.5253 - val_loss: 1.3149\n",
            "Epoch 8/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 413ms/step - accuracy: 0.7282 - loss: 0.8298 - val_accuracy: 0.5758 - val_loss: 1.2780\n",
            "Epoch 9/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 499ms/step - accuracy: 0.7694 - loss: 0.6938 - val_accuracy: 0.5960 - val_loss: 1.3562\n",
            "Epoch 10/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 533ms/step - accuracy: 0.8075 - loss: 0.5848 - val_accuracy: 0.5556 - val_loss: 1.2797\n",
            "Epoch 11/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 404ms/step - accuracy: 0.8185 - loss: 0.5846 - val_accuracy: 0.6465 - val_loss: 1.2484\n",
            "Epoch 12/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 515ms/step - accuracy: 0.8502 - loss: 0.4628 - val_accuracy: 0.4444 - val_loss: 1.5704\n",
            "Epoch 13/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 540ms/step - accuracy: 0.8771 - loss: 0.3808 - val_accuracy: 0.5354 - val_loss: 1.3049\n",
            "Epoch 14/25\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.9478 - loss: 0.2590 - val_accuracy: 0.5960 - val_loss: 1.3635\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.5796 - loss: 1.4900\n",
            "\n",
            "Final Test Accuracy: 0.5444\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step\n",
            "\n",
            "--- Sample Predictions ---\n",
            "\n",
            "Text:\n",
            "seeing that the wind speed is always changing it is easily to understand that the energy content of the wind is also always varying but many factors influence these variations like the weather the obstacles or the local surface conditions as experienced during <OOV> or thunderstorms when wind speed ...\n",
            "Actual: Information/Explanation\n",
            "Predicted: Information/Explanation\n",
            "\n",
            "Text:\n",
            "categories the sexy red <OOV> i'd idly considered getting a scooter for several years it seemed like a fun thing to do then last year as i was going through job changes and other stuff i decided to pursue the dream as a kind of distraction as many of you know i took delivery of a beautiful red <OOV>...\n",
            "Actual: Opinion/Argumentation\n",
            "Predicted: Prose/Lyrical\n",
            "\n",
            "Text:\n",
            "welcome to the gamecube hardware cheat page on cheat genius we strive to get as many gamecube hardware cheats cheat codes hints and tips for the gamecube as possible if you do not see any cheats below than we must not be able to find any cheats for this game and we should have some asap we last foun...\n",
            "Actual: Instruction\n",
            "Predicted: Instruction\n",
            "\n",
            "Text:\n",
            "your blood saves lives your blood donation is an amazing gift to people who need it in an emergency or for on going medical treatment we need over 6 000 people to give blood every day to meet the needs of hospitals and patients find out how donated blood is used <OOV> <OOV> <OOV> <OOV> <OOV> <OOV> <...\n",
            "Actual: Promotion\n",
            "Predicted: Promotion\n",
            "\n",
            "Text:\n",
            "<OOV> a rao born july 29 1973 is an american actor who has appeared in feature films and television series he starred in sam <OOV> ' s horror film drag me to hell 2009 james cameron ' s science fiction film avatar 2009 and christopher nolan ' s thriller inception 2010 <OOV> first role after graduati...\n",
            "Actual: Information/Explanation\n",
            "Predicted: Information/Explanation\n"
          ]
        }
      ]
    }
  ]
}